{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51da1519",
   "metadata": {},
   "source": [
    "## Initialization (#init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1471363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491/2148414473.py:28: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>div.output_area pre {white-space: pre;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas\n",
    "import tabulate\n",
    "import pickle\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "from statistics import mean\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "ClassifyBy = Enum('ClassifyBy', ('Levels', 'Stats', 'Group', 'StatsOnly'))\n",
    "ALL_CLASSIFICATIONS = (\n",
    "    ClassifyBy.Levels, \n",
    "    ClassifyBy.Stats, \n",
    "    ClassifyBy.StatsOnly, \n",
    "    ClassifyBy.Group\n",
    ")\n",
    "# Classification method\n",
    "DEFAULT_CLASSIFICATION = ClassifyBy.Group\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))\n",
    "\n",
    "PREFIX = \"/home/debian/bench/\"\n",
    "PREFIX2 = \"/home/debian/home1/bench/\"\n",
    "PREFIX3 = \"/home1/debian/bench/\"\n",
    "\n",
    "db = None\n",
    "def load_db():\n",
    "    global db\n",
    "    with open('db.pickle', 'rb') as handle:\n",
    "        db = pickle.load(handle)\n",
    "load_db()\n",
    "\n",
    "# Directory, where figures are stored\n",
    "FIGS_DIR = \"figs\"\n",
    "if not os.path.exists(FIGS_DIR):\n",
    "    os.mkdir(FIGS_DIR)\n",
    "\n",
    "def to_range(i):\n",
    "    i_range = len(str(i))\n",
    "    if i_range < 11:\n",
    "        return f\"{10**(i_range-1)}-{10**i_range - 1}\"\n",
    "    else:\n",
    "        return f\"{10**10}+\"\n",
    "          \n",
    "def is_real(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False        \n",
    "\n",
    "def value_to_float(val, timeout):\n",
    "    if val.startswith('TO') or val == 'ERR':\n",
    "        return timeout\n",
    "    else:\n",
    "        return np.NaN\n",
    "    \n",
    "def to_float_with_timeout(series, timeout):\n",
    "    return [float(f) if is_real(f) else value_to_float(f, timeout) for f in series]\n",
    "\n",
    "def df_to_float(df, timeout, allow_timeouts=False):\n",
    "    return df.apply(lambda x: to_float_with_timeout(x, timeout)).dropna(how='all', axis='columns')\n",
    "\n",
    "def unify_tool(tool):\n",
    "    return tool_to_output[\n",
    "        tool.replace('-runtime','').replace('-backward','-bwd').replace('-nt','').replace('-min','').replace('-incl','')\n",
    "    ]\n",
    "        \n",
    "def get_benchmark_name(bench, classification=DEFAULT_CLASSIFICATION):\n",
    "    if classification == ClassifyBy.Stats:\n",
    "        if bench not in db.keys() or 'max_square' not in db[bench].keys() or 'afa_transitions' not in db[bench].keys(): \n",
    "            return \"?\" \t\n",
    "        level = get_benchmark_name(bench, ClassifyBy.Levels)\n",
    "        square = to_range(db[bench]['max_square'])\n",
    "        trans = to_range(db[bench]['afa_transitions'])\n",
    "        return f\"{level}: {str(trans).rjust(10)} transitions, {str(square).rjust(10)} size\"\n",
    "    elif classification == ClassifyBy.StatsOnly:\n",
    "        if bench not in db.keys() or 'max_square' not in db[bench].keys() or 'afa_transitions' not in db[bench].keys(): \n",
    "            return \"?\" \t\n",
    "        afa_terms = to_range(db[bench].get('afa-minterms', '?'))\n",
    "        square = to_range(db[bench]['max_square'])\n",
    "        trans = to_range(db[bench]['afa_transitions'])\n",
    "        trans_square = to_range(db[bench]['afa_transitions']*db[bench]['max_square'])\n",
    "        #return f\"{str(trans).rjust(10)} transitions, {str(square).rjust(10)} size\"\n",
    "        return f\"{afa_terms}\"\n",
    "    elif classification == ClassifyBy.Levels:\n",
    "        d = os.path.dirname(bench).split(os.sep)\n",
    "        return os.path.join(*d[:{\n",
    "            'armc-inclusion': 2, \n",
    "            'bool_comb': 3, \n",
    "            'email_filter': 1, \n",
    "            'noodler_cut': 2, \n",
    "            'noodler_hard': 2,\n",
    "            'ltl_afa': 3,\n",
    "            'stranger_afa': 1,\n",
    "        }.get(d[0], 1)])\n",
    "    elif classification == ClassifyBy.Group:\n",
    "        if 'bool_comb/ere/QF_SLIA_Norn' in bench or 'bool_comb/ere/QF_S_sygus_qgen' in bench:\n",
    "            return 'b-smt'\n",
    "        elif 'email_filter' in bench:\n",
    "            return 'b-regex'\n",
    "        elif 'bool_comb/ere/boolean_and_loops' in bench or 'bool_comb/ere/date' in bench or 'bool_comb/ere/det_blowup' in bench or 'bool_comb/ere/password' in bench:\n",
    "            return 'b-hand-made'\n",
    "        elif 'armc-inclusion' in bench or \"automata_inclusion\" in bench:\n",
    "            return 'b-armc-incl'\n",
    "        elif 'bool_comb/cox' in bench or 'bool_comb/intersect' in bench:\n",
    "            return 'b-param'\n",
    "        elif 'ltl_afa/random_ltl' in bench:\n",
    "            return 'a-ltl-rand'\n",
    "        elif 'ltl_afa/parametric_ltl' in bench:\n",
    "            return 'a-ltl-param'\n",
    "        elif 'ltl_afa/created_ltl/nasa' in bench:\n",
    "            # might include ltl_afa/created_ltl more\n",
    "            return 'a-ltl-spec'\n",
    "        elif 'ltl_afa/created_ltl/LTLf' in bench:\n",
    "            # temporary include ltl_afa/created_ltl more\n",
    "            return 'a-ltlf-patterns'\n",
    "        elif 'ltl_afa/created_ltl/LTL-' in bench:\n",
    "            # temporary include ltl_afa/created_ltl more\n",
    "            return 'a-ltl'\n",
    "        elif 'stranger_afa' in bench:\n",
    "            return 'a-sloth'\n",
    "        elif 'noodler' in bench:\n",
    "            return 'a-noodler'\n",
    "        else:\n",
    "            d = os.path.dirname(bench).split(os.sep)\n",
    "            return f\"? {'_'.join(d[:2])}\"\n",
    "\n",
    "def save_figure(fig, ext=\".png\"):\n",
    "    tgt = os.path.join(FIGS_DIR, fig + ext)    \n",
    "    print(f\"Saving to {tgt}\")\n",
    "    if ext == \".png\":\n",
    "        plt.savefig(tgt, backend=\"cairo\", bbox_inches=\"tight\", pad_inches=0.2)\n",
    "    else:\n",
    "        plt.savefig(tgt, bbox_inches=\"tight\", pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a13ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_to_latex = {\n",
    "    'bwIC3': '\\\\abc',\n",
    "    'Antisat': '\\\\minisat',\n",
    "    'Automata': '\\\\dotnet',\n",
    "    'Bisim': '\\\\bisim',\n",
    "    'Brics': '\\\\brics',\n",
    "    'CVC5': '\\\\cvc',\n",
    "    'JaltImpact': '\\\\jaltimpact' ,\n",
    "    'eNfa': '\\\\ours',\n",
    "    'Mona': '\\mona',\n",
    "    'VATA': '\\\\vata',\n",
    "    'Z3': '\\\\zthree'\n",
    "}\n",
    "tool_to_output = {\n",
    "    'abc': 'bwIC3',\n",
    "    'afaminisat': 'Antisat',\n",
    "    'afaminisat-nt': 'Antisat',\n",
    "    'automata': 'Automata',\n",
    "    'bisim': 'Bisim',\n",
    "    'bricks': 'Brics',\n",
    "    'cvc5': 'CVC5',\n",
    "    'jaltimpact': 'JaltImpact' ,\n",
    "    'mata-nfa': 'eNfa',\n",
    "    'mona': 'Mona',\n",
    "    'vata': 'VATA',\n",
    "    'z3': 'Z3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eafb4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pandas(src: str, limit_columns_to: list[str], limit_tools_to=None, timeout=60) -> pandas.DataFrame:\n",
    "    df = pandas.read_csv(src, delimiter=';')\n",
    "    columns = [\n",
    "        col for col in df.columns \n",
    "        if (col == 'name' or any(col.endswith(limit) for limit in limit_columns_to))\n",
    "        and not col.startswith('mata-afa')\n",
    "        and not col.startswith('cvc4')\n",
    "        and (not col.startswith('afaminisat') or col.startswith('afaminisat-nt'))\n",
    "        and (not col.startswith('bricks') or col.startswith('bricks-min'))\n",
    "    ]\n",
    "    df = df[columns]\n",
    "    df['name'] = [name.replace(PREFIX, '').replace(PREFIX2, '').replace(PREFIX3, '') for name in df['name']]\n",
    "    def rounder(x):\n",
    "        if x == 'TO' or (is_real(x) and float(x) > timeout):\n",
    "            return f'TO{timeout}'\n",
    "        else:\n",
    "            return x\n",
    "    df = df.applymap(rounder)\n",
    "    return df\n",
    "\n",
    "def df_to_plottable(df, classification=DEFAULT_CLASSIFICATION, timeout=60):\n",
    "    columns = ['benchmark', 'file', 'tool', 'duration']\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        file = row['name']\n",
    "        bench = get_benchmark_name(file, classification)\n",
    "        for tool, duration in [r for r in row.items() if r[0] != 'name']:\n",
    "            if is_real(duration):\n",
    "                data.append([bench, file, unify_tool(tool), float(duration)])\n",
    "            elif duration == 'MISSING':\n",
    "                continue\n",
    "            else:\n",
    "                data.append([bench, file, unify_tool(tool), timeout])\n",
    "    return pandas.DataFrame(data, columns=columns)\n",
    "\n",
    "def df_to_times_only(df, timeout):\n",
    "    times = df[[c for c in df.columns if c.endswith('runtime')]]\n",
    "    times = df_to_float(df, timeout=timeout, allow_timeouts=True)\n",
    "    times.rename(columns={k: unify_tool(k) for k in times.columns}, inplace=True)\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c178a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = [\n",
    "    ('ArmcInclusion', 60, os.path.join('data', 'automata_inclusion-timeout-60.csv'), ),\n",
    "    ('BoolComb', 60, os.path.join('data', 'bool_comb-timeout-60.csv'), ),\n",
    "    ('EmailFilter', 60, os.path.join('data', 'email_filter-timeout-60.csv'), ),\n",
    "    ('LtlAfa', 60, os.path.join('data', 'ltl_afa-timeout-60.csv'), ),\n",
    "    ('Noodler', 60, os.path.join('data', 'noodler-timeout-60.csv'), ),\n",
    "    ('StrangerAfa', 60, os.path.join('data', 'stranger_afa-timeout-60.csv'), ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa22605",
   "metadata": {},
   "source": [
    "## Input dataframe (#dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bf416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_map = {}\n",
    "times_map = {}\n",
    "plottable_map_per_level = {}\n",
    "plottable_map_per_grp = {}\n",
    "plottable_map_per_stats = {}\n",
    "\n",
    "for bench, timeout, src in benchmarks:\n",
    "    key = f\"{bench}#{timeout}\"\n",
    "    df = to_pandas(src, limit_columns_to=['runtime'], timeout=timeout)\n",
    "    dataframe_map[key] = df\n",
    "    plottable_map_per_level[key] = df_to_plottable(df, ClassifyBy.Levels, timeout=timeout)\n",
    "    plottable_map_per_grp[key] = df_to_plottable(df, ClassifyBy.Group, timeout=timeout)\n",
    "    plottable_map_per_stats[key] = df_to_plottable(df, ClassifyBy.Stats, timeout=timeout)\n",
    "    times_map[key] = df_to_times_only(df, timeout)\n",
    "    \n",
    "overall_df = pandas.concat([df for key, df in dataframe_map.items() ])\n",
    "overall_times = df_to_times_only(overall_df, 300)\n",
    "overall_plottable_per_group = df_to_plottable(overall_df, ClassifyBy.Group)\n",
    "overall_plottable_per_level = df_to_plottable(overall_df, ClassifyBy.Levels)\n",
    "overall_plottable_per_stats = df_to_plottable(overall_df, ClassifyBy.Stats)\n",
    "overall_plottable_per_stats_only = df_to_plottable(overall_df, ClassifyBy.StatsOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475e2e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Antisat': array([0.12156863, 0.46666667, 0.70588235, 1.        ]),\n",
       " 'Automata': array([1.        , 0.49803922, 0.05490196, 1.        ]),\n",
       " 'Bisim': array([0.17254902, 0.62745098, 0.17254902, 1.        ]),\n",
       " 'Brics': array([0.83921569, 0.15294118, 0.15686275, 1.        ]),\n",
       " 'CVC5': array([0.58039216, 0.40392157, 0.74117647, 1.        ]),\n",
       " 'JaltImpact': array([0.54901961, 0.3372549 , 0.29411765, 1.        ]),\n",
       " 'Mona': array([0.89019608, 0.46666667, 0.76078431, 1.        ]),\n",
       " 'VATA': array([0.49803922, 0.49803922, 0.49803922, 1.        ]),\n",
       " 'Z3': array([0.7372549 , 0.74117647, 0.13333333, 1.        ]),\n",
       " 'bwIC3': array([0.09019608, 0.74509804, 0.81176471, 1.        ]),\n",
       " 'eNfa': array([0.61960784, 0.85490196, 0.89803922, 1.        ])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = sorted([unify_tool(t) for t in overall_df.columns if t != 'name' and t != 'bench'])\n",
    "tool_len = len(tools)\n",
    "color_map = {\n",
    "    t: c for (t, c) in zip(tools, mpl.colormaps['tab20'].resampled(tool_len).colors)\n",
    "}\n",
    "color_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd5170",
   "metadata": {},
   "source": [
    "## Summary of statistics (#stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78aac64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\hline\n",
      " tool        & \\multicolumn{3}{c}{a-ltl-param}   & \\multicolumn{3}{c}{a-ltl-rand}   & \\multicolumn{3}{c}{a-ltl-spec}   & \\multicolumn{3}{c}{a-ltlf-patterns}   & \\multicolumn{3}{c}{a-noodler}   & \\multicolumn{3}{c}{a-sloth}   \\\\\n",
      "\\hline\n",
      " \\abc        & 25.4 & {0.6} & 134                & {0.1} & {0.1} & {0}              & {0.1} & {0.1} & {0}              & {0.1} & {0.1} & {0}                   & {0.1} & {0.1} & {3}             & {1.3} & {0.1} & 34            \\\\\n",
      " \\bisim      & 58.2 & 60.0 & 308                 & {4.4} & {1.0} & {8}              & 32.9 & 60.0 & 32                 & 37.0 & 60.0 & 1013                    & 31.6 & 26.4 & 6644(8)           & 17.5 & {1.5} & 1087(10)       \\\\\n",
      " \\jaltimpact & 47.0 & 60.0 & 205                 & {7.9} & {2.3} & 12               & {2.4} & {1.4} & 0(1)             & {4.0} & {2.8} & {0}                   & {3.8} & {1.8} & 186             & 24.1 & 15.4 & 958             \\\\\n",
      " \\minisat    & 58.3 & 60.0 & 310                 & 18.3 & {0.1} & 84                & {0.0} & {0.0} & {0}              & 31.0 & 60.0 & 868                     & {0.4} & {0.0} & 57              & 14.9 & {0.0} & 991            \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "[['\\\\abc', '{5.2} & {1.1} & {1}', '{0.4} & {0.1} & {0}', '{0.2} & {0.1} & {0}', '{0.1} & {0.1} & {0}', '44.9 & 60.0 & 191'], ['\\\\bisim', '28.5 & {9.5} & 72', '11.2 & {1.0} & {8}', '{3.8} & {1.3} & 15', '{2.5} & {2.5} & {0}', '55.4 & 60.0 & 240'], ['\\\\brics', '\\\\multicolumn{3}{c|}{-}', '{3.9} & {0.4} & {3}', '{5.8} & {0.8} & 40', '{0.3} & {0.3} & {0}', '52.7 & 60.0 & 228'], ['\\\\cvc', '\\\\multicolumn{3}{c|}{-}', '27.4 & {0.8} & 10(15)', '\\\\multicolumn{3}{c|}{-}', '{0.8} & {0.2} & {1}', '48.6 & 60.0 & 208'], ['\\\\dotnet', '{3.5} & {0.4} & {9}', '{0.2} & {0.2} & {0}', '{0.2} & {0.2} & {0}', '{0.2} & {0.2} & {0}', '46.3 & 60.0 & 161(42)'], ['\\\\jaltimpact', '30.9 & 24.6 & 63', '11.1 & {3.6} & {5}', '12.2 & {2.4} & 48', '{3.5} & {3.5} & {0}', '57.8 & 60.0 & 252'], ['\\\\minisat', '42.8 & 60.0 & 118', '{1.4} & {0.0} & {1}', '{9.3} & {1.4} & 45', '{0.0} & {0.0} & {0}', '39.0 & 60.0 & 147'], ['\\\\mona', '28.5 & 44.1 & 43', '27.3 & {0.1} & 22(3)', '41.0 & 60.0 & 15(298)', '{1.5} & {0.0} & {8}', '44.9 & 60.0 & 25(169)'], ['\\\\ours', '{1.9} & {0.8} & {0}', '{0.1} & {0.0} & {0}', '{0.2} & {0.1} & {0}', '{0.0} & {0.0} & {0}', '44.6 & 60.0 & 143(51)'], ['\\\\vata', '{2.6} & {3.4} & {0}', '{0.1} & {0.0} & {0}', '{2.1} & {0.2} & 10(1)', '{0.0} & {0.0} & {0}', '37.8 & 60.0 & 155(1)'], ['\\\\zthree', '\\\\multicolumn{3}{c|}{-}', '{3.9} & {0.0} & {2}', '\\\\multicolumn{3}{c|}{-}', '{0.4} & {0.0} & {2}', '32.0 & 48.1 & 129']]\n",
      "tool         \\multicolumn{3}{c}{b-armc-incl}    \\multicolumn{3}{c}{b-hand-made}    \\multicolumn{3}{c}{b-regex}    \\multicolumn{3}{c}{b-smt}    \\multicolumn{3}{c}{b-param}\n",
      "-----------  ---------------------------------  ---------------------------------  -----------------------------  ---------------------------  -----------------------------\n",
      "\\abc         {5.2} & {1.1} & {1}                {0.4} & {0.1} & {0}                {0.2} & {0.1} & {0}            {0.1} & {0.1} & {0}          44.9 & 60.0 & 191\n",
      "\\bisim       28.5 & {9.5} & 72                  11.2 & {1.0} & {8}                 {3.8} & {1.3} & 15             {2.5} & {2.5} & {0}          55.4 & 60.0 & 240\n",
      "\\brics       \\multicolumn{3}{c|}{-}             {3.9} & {0.4} & {3}                {5.8} & {0.8} & 40             {0.3} & {0.3} & {0}          52.7 & 60.0 & 228\n",
      "\\cvc         \\multicolumn{3}{c|}{-}             27.4 & {0.8} & 10(15)              \\multicolumn{3}{c|}{-}         {0.8} & {0.2} & {1}          48.6 & 60.0 & 208\n",
      "\\dotnet      {3.5} & {0.4} & {9}                {0.2} & {0.2} & {0}                {0.2} & {0.2} & {0}            {0.2} & {0.2} & {0}          46.3 & 60.0 & 161(42)\n",
      "\\jaltimpact  30.9 & 24.6 & 63                   11.1 & {3.6} & {5}                 12.2 & {2.4} & 48              {3.5} & {3.5} & {0}          57.8 & 60.0 & 252\n",
      "\\minisat     42.8 & 60.0 & 118                  {1.4} & {0.0} & {1}                {9.3} & {1.4} & 45             {0.0} & {0.0} & {0}          39.0 & 60.0 & 147\n",
      "\\mona        28.5 & 44.1 & 43                   27.3 & {0.1} & 22(3)               41.0 & 60.0 & 15(298)          {1.5} & {0.0} & {8}          44.9 & 60.0 & 25(169)\n",
      "\\ours        {1.9} & {0.8} & {0}                {0.1} & {0.0} & {0}                {0.2} & {0.1} & {0}            {0.0} & {0.0} & {0}          44.6 & 60.0 & 143(51)\n",
      "\\vata        {2.6} & {3.4} & {0}                {0.1} & {0.0} & {0}                {2.1} & {0.2} & 10(1)          {0.0} & {0.0} & {0}          37.8 & 60.0 & 155(1)\n",
      "\\zthree      \\multicolumn{3}{c|}{-}             {3.9} & {0.0} & {2}                \\multicolumn{3}{c|}{-}         {0.4} & {0.0} & {2}          32.0 & 48.1 & 129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491/3759042613.py:9: RuntimeWarning: Mean of empty slice\n",
      "  round(np.nanmean(vals), 1),\n",
      "/home/raph/.virtualenvs/py39/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n"
     ]
    }
   ],
   "source": [
    "cols = 3\n",
    "def count_short_stats(series):\n",
    "    global cols\n",
    "    vals = [float(v) if is_real(v) else value_to_float(v, 60) for v in series] or [-1]\n",
    "    if cols == 3:\n",
    "        to_len = len([s for s in series if str(s).startswith('TO')])\n",
    "        err_len = len([s for s in series if str(s).startswith('ERR')])\n",
    "        return (\n",
    "            round(np.nanmean(vals), 1), \n",
    "            round(np.nanmedian(vals), 1), \n",
    "            f\"{to_len}\" if err_len == 0 else f\"{to_len}({err_len})\"\n",
    "        )\n",
    "    else:\n",
    "        return (round(np.nanmean(vals), 1), len([s for s in series if str(s).startswith('TO')]))\n",
    "grp_df = overall_df.copy()\n",
    "grp_df['benchmark'] = [get_benchmark_name(b, ClassifyBy.Group) for b in grp_df['name']]\n",
    "grp_df = grp_df[[c for c in grp_df.columns if c != 'name']]\n",
    "#grp_df.groupby('benchmark').agg(['mean', 'median', count_timeouts])\n",
    "b_param = 'b-param'\n",
    "benchmark_names = sorted(list(set(grp_df['benchmark'])))\n",
    "benchmark_names = [b for b in benchmark_names if b != b_param] + [b_param]\n",
    "headers = ['tool'] + [\"\\\\multicolumn{{{1}}}{{c}}{{{0}}}\".format(b, cols) for b in benchmark_names]\n",
    "data = []\n",
    "def is_win(c):\n",
    "    if is_real(c) and float(c) < 10:\n",
    "        return '{{{0}}}'.format(c)\n",
    "    else:\n",
    "        return str(c)\n",
    "def to_cell(stats, n):\n",
    "    cell = stats.get(n, '-')\n",
    "    if cell == '-' or (np.isnan(cell[0]) and (cell[-1] == 0 or cell[-1] == '0')):\n",
    "        return '\\\\multicolumn{{{0}}}{{c|}}{{-}}'.format(cols)\n",
    "    else:\n",
    "        #return f\"{cell[0]} | {cell[1]} | {cell[2]}\"\n",
    "        if cols == 3:\n",
    "            return f\"{is_win(cell[0])} & {is_win(cell[1])} & {is_win(cell[2])}\"\n",
    "        else:\n",
    "            return f\"{is_win(cell[0])} & {is_win(cell[1])}\"\n",
    "grp_items = grp_df.groupby('benchmark').agg(count_short_stats).items()\n",
    "for group in grp_items:\n",
    "    if group[0] == 'bench':\n",
    "        continue\n",
    "    tool = tool_to_latex[unify_tool(group[0])]\n",
    "    stats = group[1].to_dict()\n",
    "    data.append([tool] + [to_cell(stats, n) for n in benchmark_names])\n",
    "data = sorted(data, key=lambda x: x[0])\n",
    "dheaders = headers[:7]\n",
    "ddata = [d[:7] for d in [data[0], data[1], data[5], data[6]]]\n",
    "print(tabulate.tabulate(ddata, headers=dheaders, tablefmt='latex_raw'))\n",
    "with open(os.path.join('figs', 'afa-stats.html'), 'w') as stats_handle:\n",
    "    stats_handle.write(tabulate.tabulate(ddata, headers=dheaders, tablefmt='html'))\n",
    "with open(os.path.join('figs', f'afa-stats{\"-mean-only\" if cols == 2 else \"\"}.tex'), 'w') as stats_handle:\n",
    "    stats_handle.write(\"\\n\".join(tabulate.tabulate(ddata, headers=dheaders, tablefmt='latex_raw').split(\"\\n\")[2:-1]))\n",
    "dheaders = ['tool'] + headers[7:]\n",
    "ddata = [[d[0]] + d[7:] for d in data]\n",
    "print(ddata)\n",
    "with open(os.path.join('figs', 'bre-stats.html'), 'w') as stats_handle:\n",
    "    stats_handle.write(tabulate.tabulate(ddata, headers=dheaders, tablefmt='html'))\n",
    "with open(os.path.join('figs', f'bre-stats{\"-mean-only\" if cols == 2 else \"\"}.tex'), 'w') as stats_handle:\n",
    "    stats_handle.write(\"\\n\".join(tabulate.tabulate(ddata, headers=dheaders, tablefmt='latex_raw').split(\"\\n\")[2:-1]))\n",
    "print(tabulate.tabulate(ddata, headers=dheaders))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8277bfd8",
   "metadata": {},
   "source": [
    "## Lineplot (#line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb4f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_generator(series, timeout):\n",
    "    sum = 0\n",
    "    for num in series:\n",
    "        if num >= timeout:\n",
    "            yield None\n",
    "        else:\n",
    "            sum += num\n",
    "            yield sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b854451",
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_map = {\n",
    "    'bwIC3': (0, ()),\n",
    "    'Bisim': (0, (1, 1)),\n",
    "    'Brics': (0, ()),\n",
    "    'Automata': (0, (1, 1)),\n",
    "    'JaltImpact': (0, ()),\n",
    "    'Mona': (0, (1, 1)),\n",
    "    'VATA': (0, ()),\n",
    "    'Z3': (0, (1, 1)),\n",
    "    'Antisat': (0, ()),\n",
    "    'CVC5': (0, (1, 1)),\n",
    "    'eNfa': (0, ()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40753bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
      "/tmp/ipykernel_3491/486621590.py:37: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  g.set_xticklabels(g.get_xticklabels(), rotation=30)\n"
     ]
    }
   ],
   "source": [
    "BEST_RATE = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(4*5, 3*6))\n",
    "plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.1, wspace=0.1)\n",
    "bench_list = ['a-ltlf-patterns', 'a-ltl-rand', 'a-sloth', 'a-noodler', 'a-ltl-spec', 'b-hand-made', 'b-armc-incl', 'b-regex', 'b-smt']\n",
    "bench_to_y = {\n",
    "    'a-ltlf-patterns': 10**4, 'a-ltl-rand': 10**3, 'a-sloth': 10**4, 'a-noodler': 10**4, 'a-ltl-spec': 10**2,\n",
    "    'b-hand-made': 10**1, 'b-armc-incl': 10**2, 'b-regex': 10**2, 'b-smt': 10**2}\n",
    "\n",
    "for key, pdf in plottable_map_per_grp.items():\n",
    "    bench, timeout = key.split('#')\n",
    "    timeout = int(timeout)\n",
    "    subgroups = set(list(pdf['benchmark']))\n",
    "    for grp in subgroups:\n",
    "        data = pdf[pdf['benchmark'] == grp]\n",
    "        if grp.endswith('-param'):\n",
    "            continue\n",
    "        i = bench_list.index(grp)\n",
    "        sums = defaultdict(list)\n",
    "        grp_name = f\"{grp}\"\n",
    "\n",
    "        for _, row in data.iterrows():\n",
    "            sums[row['tool']].append(row['duration'])\n",
    "        vdata = {}\n",
    "        for k in sorted(sums.keys()):\n",
    "            v = sums[k]\n",
    "            values = list(sum_generator(sorted(v), timeout))\n",
    "            val_len = len(values)\n",
    "            to_len = len([a for a in values if a == None])\n",
    "            if (val_len - to_len) / val_len > BEST_RATE:\n",
    "                vdata[k] = values\n",
    "        g = seaborn.lineplot(\n",
    "            vdata, linewidth=3.5, ax=ax[i // 3, i % 3], palette=color_map\n",
    "        )\n",
    "        #g.set_ylim([0, bench_to_y[grp]])\n",
    "        g.set(yscale=\"symlog\")\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
    "        g.set_title(f\"{grp_name}\", x=0.05)    \n",
    "        if i % 3 == 0:\n",
    "            g.set_ylabel(\"time [s]\")\n",
    "        if i // 3 == 2:\n",
    "            g.set_xlabel(\"benchmark\")\n",
    "        seaborn.move_legend(g, \"upper left\", bbox_to_anchor=(0., 1), frameon=True)\n",
    "        i += 1\n",
    "\n",
    "#save_figure(f\"cactus_plots_log_scale\")\n",
    "save_figure(f\"cactus_plots\")\n",
    "save_figure(f\"cactus\", ext=\".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1836e65",
   "metadata": {},
   "source": [
    "## Infering Parametric models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b2986",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['bench', 'k', 'tool', 'duration']\n",
    "def to_models(df):\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        if 'parametric_ltl' in row['name']:\n",
    "            bench_parts = row['name'].split(os.sep)\n",
    "        else:\n",
    "            bench_parts = os.path.dirname(row['name']).split(os.sep)\n",
    "        bench = os.path.join(*bench_parts[:3])\n",
    "        k = bench_parts[-1]\n",
    "        if is_real(k):\n",
    "            k = int(k)\n",
    "            for col, v in row.items():\n",
    "                if col == 'name':\n",
    "                    continue\n",
    "                tool = unify_tool(col)\n",
    "                if v == 'ERR':\n",
    "                    time = np.NaN\n",
    "                elif is_real(v):\n",
    "                    time = float(v)\n",
    "                elif v.startswith('TO'):\n",
    "                    #time = np.NaN\n",
    "                    time = int(v[2:])\n",
    "                else:\n",
    "                    continue\n",
    "                data.append([bench, k, tool, time])\n",
    "    tmp_data = sorted(data, key=lambda x: x[1])\n",
    "    to_map = defaultdict(list)\n",
    "    data = []\n",
    "    for val in tmp_data:\n",
    "        key = f\"{val[0]}:{val[2]}\"\n",
    "        if val[-1] >= 60:\n",
    "            # it's timeout:\n",
    "            if not to_map[key] or to_map[key][-1] < 60:\n",
    "                data.append(val)\n",
    "        else:\n",
    "            data.append(val) \n",
    "        to_map[key].append(val[-1])\n",
    "    models = pandas.DataFrame(data, columns=columns)\n",
    "    return models\n",
    "for key, df in dataframe_map.items():\n",
    "    models = to_models(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9282db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_to_paper_tag = {\n",
    "    'bool_comb/intersect/longstrings': 'b-param(1)',\n",
    "    'bool_comb/intersect/expbranching': 'b-param(2)',\n",
    "    'bool_comb/intersect/exppaths1': \"b-param(3?)\",\n",
    "    'bool_comb/intersect/exppaths2': \"b-param(3?)\",\n",
    "    'bool_comb/cox/diff_sat': \"b-param(4)\",\n",
    "    'bool_comb/cox/diff_unsat': \"b-param(5)\",\n",
    "    'bool_comb/cox/inter_sat': \"b-param(6)\",\n",
    "    'bool_comb/cox/inter_unsat': \"b-param(7)\",\n",
    "    'ltl_afa/created_ltl/LTLf-specific': '??',\n",
    "    'ltl_afa/parametric_ltl/lift_afas': 'a-param(Lift)',\n",
    "    'ltl_afa/parametric_ltl/counter_afas': 'a-param(Counter)',\n",
    "}\n",
    "bench_to_paper = {\n",
    "    'bool_comb/intersect/longstrings': 'longstrings',\n",
    "    'bool_comb/intersect/expbranching': 'expbranching',\n",
    "    'bool_comb/intersect/exppaths1': \"exppaths1\",\n",
    "    'bool_comb/intersect/exppaths2': \"exppaths2\",\n",
    "    'bool_comb/cox/diff_sat': \"diff_sat\",\n",
    "    'bool_comb/cox/diff_unsat': \"diff_unsat\",\n",
    "    'bool_comb/cox/inter_sat': \"inter_sat\",\n",
    "    'bool_comb/cox/inter_unsat': \"inter_unsat\",\n",
    "    'ltl_afa/created_ltl/LTLf-specific': 'LTLf-specific',\n",
    "    'ltl_afa/parametric_ltl/lift_afas': 'lift_afas',\n",
    "    'ltl_afa/parametric_ltl/counter_afas': 'counter_afas',\n",
    "}\n",
    "\n",
    "\n",
    "f, axs = plt.subplots(4, 3, figsize=(20, 6))\n",
    "plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.5, wspace=0.0)\n",
    "i = 0\n",
    "for key in sorted(dataframe_map.keys()):\n",
    "    df = dataframe_map[key]\n",
    "    models = to_models(df)\n",
    "    for bench in sorted(set(models['bench'])):\n",
    "        if bench in ('ltl_afa/created_ltl/LTLf-specific',):\n",
    "            continue\n",
    "        #data_df = models[models['bench'] == bench].dropna()\n",
    "        data_df = models[models['bench'] == bench]\n",
    "        #g = seaborn.pointplot(\n",
    "        g = seaborn.pointplot(\n",
    "            data_df, x=\"k\", y=\"duration\", hue=\"tool\", errorbar=None, \n",
    "            ax=axs[i // 3, i % 3], palette=color_map, markers='o',\n",
    "            #linewidth=3, \n",
    "        )\n",
    "        g.legend([],[], frameon=False)\n",
    "        g.set_ylim([0, 60])\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
    "        tick_rate = len(g.get_xticklabels()) // 10\n",
    "        if tick_rate != 0:\n",
    "            for index, label in enumerate(g.get_xticklabels()):\n",
    "                if index % tick_rate == 0:\n",
    "                    label.set_visible(True)\n",
    "                else:\n",
    "                    label.set_visible(False)\n",
    "        #g.set_title(f\"{grp_name}\", x=0.05)  \n",
    "        #g.set(title=f\"{bench_to_paper[bench]}\", x=0.05)\n",
    "        g.set_title(f\"{bench_to_paper[bench]}\", x=0.05)\n",
    "        if i % 3 != 0:\n",
    "            g.set(yticklabels=[])\n",
    "            g.set(ylabel=None)\n",
    "        seaborn.move_legend(g, \"upper right\", bbox_to_anchor=(1, 1), ncols=2)\n",
    "        i += 1\n",
    "        if i == 4 or i == 7:\n",
    "            i += 1\n",
    "i = 4\n",
    "axs[i // 3, i % 3].set(xlabel=None)\n",
    "axs[i // 3, i % 3].set(yticklabels=[])\n",
    "axs[i // 3, i % 3].set(xticklabels=[])\n",
    "axs[i // 3, i % 3].set(xticks=[])\n",
    "axs[i // 3, i % 3].set(yticks=[])\n",
    "axs[i // 3, i % 3].spines['top'].set_visible(False)\n",
    "axs[i // 3, i % 3].spines['bottom'].set_visible(False)\n",
    "\n",
    "i = 7\n",
    "axs[i // 3, i % 3].legend(\n",
    "    handles=[\n",
    "        Line2D(\n",
    "            [0], [0], color='w', marker='o', markerfacecolor=color_map[tool], label=f\"{tool}\", \n",
    "            markersize=10,\n",
    "        )\n",
    "        for tool in sorted(color_map.keys())\n",
    "    ], ncols=2, loc='lower center', fontsize='18'\n",
    ")\n",
    "axs[i // 3, i % 3].set(xlabel=None)\n",
    "axs[i // 3, i % 3].set(yticklabels=[])\n",
    "axs[i // 3, i % 3].set(xticklabels=[])\n",
    "axs[i // 3, i % 3].set(xticks=[])\n",
    "axs[i // 3, i % 3].set(yticks=[])\n",
    "axs[i // 3, i % 3].spines['top'].set_visible(False)\n",
    "axs[i // 3, i % 3].spines['bottom'].set_visible(False)\n",
    "save_figure(f'models_overview')\n",
    "save_figure(f'models', ext='.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1349a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overall_df['bench'] = [get_benchmark_name(n) for n in overall_df['name']]\n",
    "benches = sorted([b for b in sorted(list(set(overall_df['bench']))) if not b.endswith('-param')])\n",
    "print(f\"{len(benches)}: {benches}\")\n",
    "\n",
    "winners = {\n",
    "    'a-ltl': ['abc', 'jaltimpact', 'afaminisat-nt'], \n",
    "    'a-ltlf-patterns': ['abc', 'jaltimpact', 'afaminisat-nt'], \n",
    "    'a-ltl-param': ['abc', 'jaltimpact', 'bisim'], \n",
    "    'a-ltl-rand': ['abc', 'bisim', 'jaltimpact'], \n",
    "    #'a-sloth': ['abc', 'afaminisat-nt', 'bisim'],  # by means\n",
    "    'a-sloth': ['abc', 'afaminisat-nt', 'jaltimpact'], # by timeouts\n",
    "    'a-noodler': ['abc', 'afaminisat-nt', 'jaltimpact'], \n",
    "    'a-ltl-spec': ['afaminisat-nt', 'abc', 'jaltimpact'], \n",
    "    'b-hand-made': ['automata', 'mata-nfa', 'vata'], # remove abc\n",
    "    'b-armc-incl': ['vata', 'mata-nfa', 'automata'], \n",
    "    'b-param': ['z3', 'afaminisat-nt', 'vata'],  #by to\n",
    "    'b-regex': ['automata', 'abc', 'mata-nfa'], \n",
    "    'b-smt': ['afaminisat-nt', 'mata-nfa', 'vata']\n",
    "}\n",
    "indices = [(1, 2), (1, 3), (2, 3)]\n",
    "bench_colors = mpl.colormaps['tab10'].resampled(len(benches)).colors\n",
    "fig = plt.figure(constrained_layout=True, figsize=(4*5, 3*2.5))\n",
    "plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=0.1, wspace=0.3)\n",
    "subfigs = fig.subfigures(3, 3)\n",
    "for i, subfig in enumerate(subfigs.flat):\n",
    "    if i == len(benches):\n",
    "        break\n",
    "    subfig.suptitle(f\"{benches[i]}\")\n",
    "    axs = subfig.subplots(1, 3)\n",
    "    bench = benches[i]\n",
    "    bench_df = df_to_float(overall_df[overall_df['bench'] == bench], 60, allow_timeouts=True)\n",
    "    for ii, ax in enumerate(axs.flat):\n",
    "        lhs, rhs = indices[ii]\n",
    "        lhs, rhs = winners[bench][lhs-1], winners[bench][rhs-1]\n",
    "        ax.grid(True, which='both', linestyle='--')\n",
    "        ax.set_xlabel(f\"{tool_to_output[lhs]}\")\n",
    "        ax.set_ylabel(f\"{tool_to_output[rhs]}\")\n",
    "        ax.scatter(\n",
    "            bench_df[f\"{lhs}-runtime\"], bench_df[f\"{rhs}-runtime\"], marker= 'x', c=[bench_colors[i]]\n",
    "        )\n",
    "        #pt = min(min(ax.get_xlim()[1], ax.get_ylim()[1]), 60)\n",
    "        pt = min(max(ax.get_xlim()[1], ax.get_ylim()[1]), 60)\n",
    "        ax.plot([0, pt], [0, pt], linestyle='--', color='red')\n",
    "save_figure(\"scatter_plots\")\n",
    "save_figure(\"scatter\", ext=\".pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecdb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing experiments complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
